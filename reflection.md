> 说明：本日志记录我在完成项目过程中的真实思考、决策与调试过程。部分内容为对过程的回忆整理与排版，不等同于原始聊天原文逐字记录。有ai润色辅助

---

## 1. 项目启动与问题定义

### 1.1 为什么选择这个主题
我对 kNN 的最初印象是“概念简单、效果还不错”。当作业要求“构造能让模型失败的反例”时，我更关心的是：  
- kNN 的“失败”到底长什么样？能否用可视化让它变得直观？  
- 大模型会给出哪些弱点判断？这些判断是否真的能在实验里复现？  
- 我能否把“理论弱点”变成“可运行的实验与证据图”？

### 1.2 我是如何提出问题的
一开始我并没有明确要“改进”算法，而是希望先检验：**大模型给的弱点建议是否可靠、是否可验证**。  
我给大模型的核心提问大致是：

> kNN 在什么情况下会表现明显变差？请给出可用实验验证的失败场景，并建议我怎么做可视化/对照实验。

我之所以这样问，是为了：
1. 强调“可验证”，避免停留在纯概念讨论；  
2. 逼迫回答落到具体实验形式（例如边界图/准确率曲线）；  
3. 让后续写报告时能对应“预测→验证→结论”。

---

## 2. 实验设计与执行过程

### 2.1 困难与解决：把理论变成实验

#### 困难 A：维度灾难怎么“看见”？
模型说“维度升高后距离趋于相似”，但我最困惑的是：
- “趋于相似”怎么量化或展示？
- 需要多少维度才能看到明显趋势？
- 我该用什么指标呈现（准确率？距离分布？）

**我的处理方式**：
1. 先接受一个最简单的呈现：**维度从低到高变化，记录测试集准确率**；  
2. 把它画成曲线图，作为“维度灾难”的直观证据；  
3. 维度范围先从小规模开始尝试，能跑通、能出趋势后再扩展。

> 本次项目中，我最终以“准确率随维度变化曲线图”为主证据（对应图：`results/dim_curse.png`）。  
> 更细的距离统计（例如距离分布/方差）属于可扩展项，未作为本次提交核心结果。

---

### 2.2 困难与解决：可视化代码报错与调试

#### 困难 B：AI 生成的代码不能直接跑
在做决策边界图时，我遇到过几类典型问题：
- 函数/变量名不一致（例如引用了未定义函数）
- 参数拼写错误或不符合库规范（看起来“像真的”，但运行报错）
- 图像显示不出来（GUI 环境/后端问题），需要改为保存图片

**我的调试策略变化**：
1. 第一反应：把报错贴给模型，让它“修”。  
2. 但我发现：模型有时会给“看起来合理”的修复方案，仍可能不适配我的环境。  
3. 后来我改成：**先理解代码逻辑，再做最小修改**，比如只改一个参数/一行导入，确保每次修改都可验证。

**最终方案**：  
为了避免显示窗口不弹出、快捷键无响应等问题，我把绘图改成**保存到 results 目录**，这样运行后直接在文件树里点开 PNG 查看。

---

### 2.3 我如何判断模型“说得不对/不够完整”

#### 案例：模型的结论往往“方向对，但细节不够”
我的体感是：模型对 kNN 的弱点判断通常是正确方向（例如噪声敏感、维度灾难），但会出现两类问题：
1. **预测太“绝对”**：比如给出某个固定维度就必然失效，这在不同数据设置下未必成立；  
2. **忽略落地成本**：它能告诉我“应该画图/对比”，但不会替我解决环境依赖、路径、保存、排错等细节。

因此我对模型建议的处理原则是：  
- “方向参考、细节自证”：先把建议变成可运行实验；  
- 结论以我跑出的图/结果为准；  
- 没做完/没跑过的内容不要写成“已验证结论”，而是写成“后续计划”。

---

## 3. 我的人工判断与调整（项目过程中做的关键决定）

### 3.1 为什么一定要有对照模型
如果只跑 kNN，得到“效果变差”，也可能是数据太难，而不是 kNN 的弱点。  
所以我加入了**决策树**作为对照：  
- 它不依赖距离度量，适合对比“距离失效/局部敏感”带来的影响；  
- 同一数据上对比更有说服力（不只是“我觉得”，而是“对照可见”）。

### 3.2 为了“能交付”，我优先保证 3 张核心图
我把本次项目的可交付证据压缩为三张图（对应 results 文件夹）：
1. **二维数据下决策边界对比**：`results/decision_boundary_case1.png`  
2. **维度增加的准确率变化曲线**：`results/dim_curse.png`  
3. **密度差异场景下的边界对比**：`results/varied_density.png`

这样做的原因是：  
- 三张图分别对应三类弱点；  
- 报告里可以清晰引用“图1/图2/图3”；  
- 不容易出现“写了很多但没有证据支撑”的风险。

---

## 4. 认知变化：我对大模型能力边界的理解

### 4.1 阶段 1：把模型当“老师”
刚开始我倾向于直接相信它的结论与建议，认为它能给出标准答案。

### 4.2 阶段 2：把模型当“理论顾问”
实验推进后我意识到：它通常能讲清理论，但对我本地环境、代码细节、参数可行性并不负责。  
因此我开始把它当作“提供思路的人”，而不是“替我下结论的人”。

### 4.3 阶段 3：把模型当“协作工具”
最终我形成的协作方式是：
1. 模型提供：弱点清单、实验框架、代码骨架  
2. 我负责：参数落地、调试排错、结果验证、写报告的解释与取舍  
3. 输出以“可复现的图/结果”为准

---

## 5. 项目收获与后续改进方向

### 5.1 本次项目的主要收获
- 我更清楚“算法弱点”需要用**可视化与对照实验**来说明，而不是只写理论。  
- 我学会了把大模型建议转换成“可跑、可保存、可引用”的结果。  
- 我也认识到：大模型会在实现细节上出错或不适配环境，不能把它当作权威。

### 5.2 如果重做一次，我会补充的内容（后续计划）
以下内容在本次提交中未作为核心证据，但值得继续做：
- 不同 k 值对结果的影响（k=1/3/5/10…）  
- 不同距离度量（欧氏/曼哈顿/余弦）对高维表现的影响  
- 记录推理时间（工程视角）来补充“可用性”评价  
- 引入真实数据集（iris/digits 等）检查现象是否仍然存在

---

## 6. 总结（一句话）
这次项目让我更明确：**大模型可以加速“找到方向”，但把方向变成可信证据，需要我自己做实验、调试和判断。**
